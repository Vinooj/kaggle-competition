{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vinooj/kaggle-competition/blob/main/housing_price_prediction/house_prices_advanced_regression_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.060408,
          "end_time": "2022-06-15T14:49:11.448301",
          "exception": false,
          "start_time": "2022-06-15T14:49:11.387893",
          "status": "completed"
        },
        "tags": [],
        "id": "dykET_WO8jQ4"
      },
      "source": [
        "### HOUSE SALE PRICING PREDICTION\n",
        "\n",
        "Hi folks! This is a beginners notebook that covers all the main steps necessary to complete a Machine Learning project. Here below you can see a detailed table of contents of the work:\n",
        "\n",
        "Uses Notebook mentioned here as the baseline: https://www.kaggle.com/code/venkatapadavala/house-prices-advanced-regression-practice\n",
        "\n",
        "**PREPROCESSING & EDA**\n",
        "\n",
        "- Importing Libraries & Data\n",
        "- Dealing with Duplicates and Nan\n",
        "- Looking at correlations\n",
        "- Data Normalization (Plots & Tests)\n",
        "\n",
        "\n",
        "**MODELING**\n",
        "\n",
        "- Baseline Models with 10-Folds CV\n",
        "- Best Model (RandomGridSearch)\n",
        "- Prediction\n",
        "- Submission"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "id": "vWwJTCiPVMIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:11.567032Z",
          "iopub.status.busy": "2022-06-15T14:49:11.566160Z",
          "iopub.status.idle": "2022-06-15T14:49:13.747074Z",
          "shell.execute_reply": "2022-06-15T14:49:13.747662Z",
          "shell.execute_reply.started": "2022-06-15T12:53:29.052845Z"
        },
        "papermill": {
          "duration": 2.242056,
          "end_time": "2022-06-15T14:49:13.747845",
          "exception": false,
          "start_time": "2022-06-15T14:49:11.505789",
          "status": "completed"
        },
        "tags": [],
        "id": "o6tQ-xE78jQ5"
      },
      "outputs": [],
      "source": [
        "# IMPORTING LIBRARIES & MAIN PATH\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import scipy.stats as stats\n",
        "from scipy.stats import norm\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import skew, norm\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action=\"ignore\")\n",
        "\n",
        "# Defining the working directories\n",
        "\n",
        "input_path1 = './sample_data/'\n",
        "input_path2 = './sample_data/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:13.867438Z",
          "iopub.status.busy": "2022-06-15T14:49:13.866722Z",
          "iopub.status.idle": "2022-06-15T14:49:14.014472Z",
          "shell.execute_reply": "2022-06-15T14:49:14.013819Z",
          "shell.execute_reply.started": "2022-06-15T12:53:29.077367Z"
        },
        "papermill": {
          "duration": 0.208048,
          "end_time": "2022-06-15T14:49:14.014608",
          "exception": false,
          "start_time": "2022-06-15T14:49:13.806560",
          "status": "completed"
        },
        "tags": [],
        "id": "IcEjnVkm8jQ5"
      },
      "outputs": [],
      "source": [
        "# IMPORTING DATA\n",
        "\n",
        "house_data = pd.read_csv(input_path2 + 'train.csv')\n",
        "test = pd.read_csv(input_path1 + 'test.csv')\n",
        "data_w = house_data.copy()\n",
        "data_w.columns = data_w.columns.str.replace(' ', '') # Replacing the white spaces in columns' names\n",
        "data_w.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:14.155701Z",
          "iopub.status.busy": "2022-06-15T14:49:14.154855Z",
          "iopub.status.idle": "2022-06-15T14:49:14.170727Z",
          "shell.execute_reply": "2022-06-15T14:49:14.170148Z",
          "shell.execute_reply.started": "2022-06-15T12:53:29.192319Z"
        },
        "papermill": {
          "duration": 0.097237,
          "end_time": "2022-06-15T14:49:14.170845",
          "exception": false,
          "start_time": "2022-06-15T14:49:14.073608",
          "status": "completed"
        },
        "tags": [],
        "id": "_DouBZBF8jQ6"
      },
      "outputs": [],
      "source": [
        "data_w.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.059783,
          "end_time": "2022-06-15T14:49:14.290192",
          "exception": false,
          "start_time": "2022-06-15T14:49:14.230409",
          "status": "completed"
        },
        "tags": [],
        "id": "eR9h55Kc8jQ6"
      },
      "source": [
        "### EDA & VISUALIZATION\n",
        "\n",
        "Before working with any kind of data it is important to understand them. A crucial step to this aim is the ***Exploratory data analysis (EDA)***: a combination of visualizations and statistical analysis (uni, bi, and multivariate) that helps us to better understand the data we are working with and to gain insight into their relationships. So, let's explore our target variable and how the other features influence it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:14.411992Z",
          "iopub.status.busy": "2022-06-15T14:49:14.410963Z",
          "iopub.status.idle": "2022-06-15T14:49:15.003763Z",
          "shell.execute_reply": "2022-06-15T14:49:15.003109Z",
          "shell.execute_reply.started": "2022-06-15T12:53:29.223202Z"
        },
        "papermill": {
          "duration": 0.654624,
          "end_time": "2022-06-15T14:49:15.003878",
          "exception": false,
          "start_time": "2022-06-15T14:49:14.349254",
          "status": "completed"
        },
        "tags": [],
        "id": "cIMP-6HV8jQ6"
      },
      "outputs": [],
      "source": [
        "# Getting the main parameters of the Normal Ditribution ()\n",
        "(mu, sigma) = norm.fit(data_w['SalePrice'])\n",
        "\n",
        "plt.figure(figsize = (12,6))\n",
        "sns.distplot(data_w['SalePrice'], kde = True, hist=True, fit = norm)\n",
        "plt.title('SalePrice distribution vs Normal Distribution', fontsize = 13)\n",
        "plt.xlabel(\"House's sale Price in $\", fontsize = 12)\n",
        "plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
        "            loc='best')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.061193,
          "end_time": "2022-06-15T14:49:15.125486",
          "exception": false,
          "start_time": "2022-06-15T14:49:15.064293",
          "status": "completed"
        },
        "tags": [],
        "id": "O4KcOi678jQ6"
      },
      "source": [
        "In literature, acceptable values for skewness are between -0.5 and 0.5 while -2 and 2 for Kurtosis. Looking at the plot, we can clearly see how the distribution does not seem to be normal, but highly right-skewed. The non-normality of our distribution is also supported by the Shapiro test for normality (p-value really small that allows us to reject the hypotesis of normality). Despite that, let's leave it like that for now, we'll deal with that later in the notebook.\n",
        "\n",
        "**Overall Takeaway:**\n",
        "The combination of a significant skewness, potentially a kurtosis outside the typical acceptable range, and a very small p-value from the Shapiro-Wilk test all strongly suggest that the 'SalePrice' distribution is not normal.\n",
        "\n",
        "**Why is this important?**\n",
        "Many statistical models and techniques assume that the data they are working with follows a normal distribution. If your target variable ('SalePrice') is not normally distributed, using models that rely on this assumption directly might lead to:\n",
        "\n",
        "*This may help us decide whether to remove these outliers before proceeding*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:15.249602Z",
          "iopub.status.busy": "2022-06-15T14:49:15.248873Z",
          "iopub.status.idle": "2022-06-15T14:49:15.258825Z",
          "shell.execute_reply": "2022-06-15T14:49:15.259309Z",
          "shell.execute_reply.started": "2022-06-15T12:53:29.559752Z"
        },
        "papermill": {
          "duration": 0.073574,
          "end_time": "2022-06-15T14:49:15.259474",
          "exception": false,
          "start_time": "2022-06-15T14:49:15.185900",
          "status": "completed"
        },
        "tags": [],
        "id": "An4h5QFD8jQ6"
      },
      "outputs": [],
      "source": [
        "# Skew and kurt\n",
        "from scipy import stats\n",
        "\n",
        "shap_t,shap_p = stats.shapiro(data_w['SalePrice'])\n",
        "\n",
        "# Overall Takeaway:\n",
        "# The combination of a significant skewness, potentially a kurtosis outside the\n",
        "# typical acceptable range, and a very small p-value from the Shapiro-Wilk test\n",
        "# all strongly suggest that the 'SalePrice' distribution is not normal.\n",
        "#\n",
        "# Why is this important?\n",
        "# Many statistical models and techniques assume that the data they are working\n",
        "# with follows a normal distribution. If your target variable ('SalePrice')\n",
        "# is not normally distributed, using models that rely on this assumption\n",
        "# directly might lead to:\n",
        "\n",
        "# This may help us decide whether to remove these outliers before proceeding\n",
        "\n",
        "print(\"Skewness: %f\" % abs(data_w['SalePrice']).skew())\n",
        "print(\"Kurtosis: %f\" % abs(data_w['SalePrice']).kurt())\n",
        "print(\"Shapiro_Test: %f\" % shap_t)\n",
        "print(\"Shapiro_Test: %f\" % shap_p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:15.412986Z",
          "iopub.status.busy": "2022-06-15T14:49:15.412219Z",
          "iopub.status.idle": "2022-06-15T14:49:15.417252Z",
          "shell.execute_reply": "2022-06-15T14:49:15.417878Z",
          "shell.execute_reply.started": "2022-06-15T12:53:29.574206Z"
        },
        "papermill": {
          "duration": 0.082787,
          "end_time": "2022-06-15T14:49:15.418029",
          "exception": false,
          "start_time": "2022-06-15T14:49:15.335242",
          "status": "completed"
        },
        "tags": [],
        "id": "JyHGWabG8jQ6"
      },
      "outputs": [],
      "source": [
        "# data_w[\"SqFtPerRoom\"] = data_w[\"GrLivArea\"] / (data_w[\"TotRmsAbvGrd\"] +\n",
        "#                                                        data_w[\"FullBath\"] +\n",
        "#                                                        data_w[\"HalfBath\"] +\n",
        "#                                                        data_w[\"KitchenAbvGr\"])\n",
        "\n",
        "# data_w['Total_Home_Quality'] = data_w['OverallQual'] + data_w['OverallCond']\n",
        "\n",
        "# data_w['Total_Bathrooms'] = (data_w['FullBath'] + (0.5 * data_w['HalfBath']) +\n",
        "#                                data_w['BsmtFullBath'] + (0.5 * data_w['BsmtHalfBath']))\n",
        "\n",
        "# data_w[\"HighQualSF\"] = data_w[\"GrLivArea\"]+data_w[\"1stFlrSF\"] + data_w[\"2ndFlrSF\"]+data_w[\"GarageArea\"]+data_w[\"TotalBsmtSF\"]\n",
        "# #train_test[\"LowQualSF\"] = train_test[\"MasVnrArea\"] +train_test[\"WoodDeckSF\"]+train_test[\"OpenPorchSF\"]+train_test[\"EnclosedPorch\"]+train_test[\"3SsnPorch\"]+train_test[\"ScreenPorch\"]+train_test[\"PoolArea\"]\n",
        "# data_w[\"QualityproductSF\"] = data_w[\"HighQualSF\"]*(data_w['OverallQual'])\n",
        "# data_w[\"Age\"] = pd.to_numeric(data_w[\"YrSold\"])-pd.to_numeric(data_w[\"YearBuilt\"])\n",
        "\n",
        "# data_w[\"Renovate\"] = pd.to_numeric(data_w[\"YearRemod/Add\"])-pd.to_numeric(data_w[\"YearBuilt\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:15.547162Z",
          "iopub.status.busy": "2022-06-15T14:49:15.545605Z",
          "iopub.status.idle": "2022-06-15T14:49:15.549226Z",
          "shell.execute_reply": "2022-06-15T14:49:15.549865Z",
          "shell.execute_reply.started": "2022-06-15T12:53:29.592404Z"
        },
        "papermill": {
          "duration": 0.06863,
          "end_time": "2022-06-15T14:49:15.550009",
          "exception": false,
          "start_time": "2022-06-15T14:49:15.481379",
          "status": "completed"
        },
        "tags": [],
        "id": "4YICnNrX8jQ6"
      },
      "outputs": [],
      "source": [
        "# data_w[\"LowQualSF\"] = data_w[\"MasVnrArea\"]+data_w[\"WoodDeckSF\"] + data_w[\"OpenPorchSF\"]+data_w[\"PoolArea\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.05985,
          "end_time": "2022-06-15T14:49:15.670180",
          "exception": false,
          "start_time": "2022-06-15T14:49:15.610330",
          "status": "completed"
        },
        "tags": [],
        "id": "SuIaSFd38jQ6"
      },
      "source": [
        "The correlation matrix is the best way to see all the numerical correlation between features. Let's see which are the feature that correlate most with our target variable.\n",
        "\n",
        "A correlation matrix is one of the most powerful tools for guiding your feature engineering strategy, specifically for deciding which features to combine versus which to potentially drop.\n",
        "\n",
        "Here’s how you can interpret it, breaking it down into two key relationships:\n",
        "\n",
        "\n",
        "# Feature Correlation Analysis Guide\n",
        "\n",
        "## 1. Correlation Between Two Predictor Features\n",
        "*Example: GarageCars vs GarageArea*\n",
        "\n",
        "**Purpose:** This tells you about redundancy between features.\n",
        "\n",
        "### What to Look For\n",
        "Look for very high correlation values (e.g., > 0.8 or < -0.8) between two different predictor features. This indicates **multicollinearity**, meaning the two features contain very similar information.\n",
        "\n",
        "### Decision Making: Combine vs. Drop\n",
        "\n",
        "#### Drop (Most Common Action)\n",
        "If GarageCars and GarageArea have a correlation of 0.9, a model doesn't need both features to understand the size of the garage. Keeping both can sometimes make linear models unstable.\n",
        "\n",
        "**Standard Practice:** Drop the feature that has the lower correlation with the target variable (SalePrice). You keep the more predictive one and discard the redundant one.\n",
        "\n",
        "#### Combine (Advanced Technique)\n",
        "You could also combine them into a new feature. For example, you could create:\n",
        "```\n",
        "Garage_Efficiency = GarageArea / GarageCars\n",
        "```\n",
        "\n",
        "This is a more advanced technique that captures a new concept (average space per car), but simply dropping the weaker feature is often sufficient.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Correlation Between a Predictor and the Target\n",
        "*Example: OverallQual vs. SalePrice*\n",
        "\n",
        "**Purpose:** This tells you about predictive power.\n",
        "\n",
        "### What to Look For\n",
        "Look for features that have a high correlation with your target variable, SalePrice. These are your strongest, most important predictors.\n",
        "\n",
        "### Decision Making: Combine vs. Drop\n",
        "\n",
        "#### Never Drop\n",
        "You would almost never drop a feature that is highly correlated with your target.\n",
        "\n",
        "#### Combine (Create Interactions)\n",
        "These strong predictors are the perfect candidates for combination. As outlined in the research report, we saw that OverallQual and GrLivArea are both highly correlated with SalePrice.\n",
        "\n",
        "**The decision to create OverallQual_x_GrLivArea comes directly from this observation.**\n",
        "\n",
        "**Hypothesis:** If each feature is individually powerful, perhaps their interaction is even more powerful. This new feature allows the model to learn that the value of an extra square foot is worth more in a high-quality house.\n",
        "\n",
        "---\n",
        "\n",
        "## Summary of the Strategy\n",
        "\n",
        "| If you see... | It means... | Your Action... | Example from Notebook |\n",
        "|---------------|-------------|----------------|----------------------|\n",
        "| **High Correlation:**<br>Predictor A vs. Predictor B | Redundancy / Multicollinearity | **Drop** the weaker of the two (the one less correlated with `SalePrice`) | `GarageArea` vs. `GarageCars` |\n",
        "| **High Correlation:**<br>Predictor A vs. Target (`SalePrice`) | High Predictive Power | **Keep** it. **Combine** it with another strong predictor to create an interaction feature | `OverallQual` vs. `SalePrice` |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:15.795574Z",
          "iopub.status.busy": "2022-06-15T14:49:15.794774Z",
          "iopub.status.idle": "2022-06-15T14:49:18.900955Z",
          "shell.execute_reply": "2022-06-15T14:49:18.901559Z",
          "shell.execute_reply.started": "2022-06-15T12:53:29.601606Z"
        },
        "papermill": {
          "duration": 3.170869,
          "end_time": "2022-06-15T14:49:18.901723",
          "exception": false,
          "start_time": "2022-06-15T14:49:15.730854",
          "status": "completed"
        },
        "tags": [],
        "id": "sW3FuWl58jQ6"
      },
      "outputs": [],
      "source": [
        "# Correlation Matrix\n",
        "\n",
        "f, ax = plt.subplots(figsize=(30, 25))\n",
        "mat = data_w.corr('pearson', numeric_only=True)\n",
        "mask = np.triu(np.ones_like(mat, dtype=bool))\n",
        "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
        "sns.heatmap(mat, mask=mask, cmap=cmap, vmax=1, center=0, annot = True,\n",
        "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.072743,
          "end_time": "2022-06-15T14:49:19.045501",
          "exception": false,
          "start_time": "2022-06-15T14:49:18.972758",
          "status": "completed"
        },
        "tags": [],
        "id": "FsnsJ4_v8jQ6"
      },
      "source": [
        "Now that we know which features correlates most with our target variable we can investigate them more in depth."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:19.194051Z",
          "iopub.status.busy": "2022-06-15T14:49:19.193310Z",
          "iopub.status.idle": "2022-06-15T14:49:19.197947Z",
          "shell.execute_reply": "2022-06-15T14:49:19.197400Z",
          "shell.execute_reply.started": "2022-06-15T12:53:32.937221Z"
        },
        "papermill": {
          "duration": 0.08199,
          "end_time": "2022-06-15T14:49:19.198061",
          "exception": false,
          "start_time": "2022-06-15T14:49:19.116071",
          "status": "completed"
        },
        "tags": [],
        "id": "zPj3SCQw8jQ6"
      },
      "outputs": [],
      "source": [
        "mat['SalePrice']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_highly_correlated_features(df, threshold=0.8):\n",
        "    \"\"\"\n",
        "    This function takes a DataFrame and a correlation threshold, and returns\n",
        "    a DataFrame of feature pairs that have a correlation greater than the\n",
        "    specified threshold.\n",
        "\n",
        "    This is useful for identifying multicollinearity and redundant features.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The input DataFrame containing the features. It should\n",
        "                           only contain numerical columns.\n",
        "        threshold (float): The correlation threshold. The function will find pairs\n",
        "                           with an absolute correlation above this value.\n",
        "                           Defaults to 0.8.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame with columns ['Feature 1', 'Feature 2', 'Correlation']\n",
        "                      listing the pairs of highly correlated features and their\n",
        "                      correlation value.\n",
        "    \"\"\"\n",
        "    # Ensure the input is a DataFrame\n",
        "    if not isinstance(df, pd.DataFrame):\n",
        "        raise TypeError(\"Input must be a pandas DataFrame.\")\n",
        "\n",
        "    # Calculate the absolute value of the correlation matrix\n",
        "    corr_matrix = df.corr().abs()\n",
        "\n",
        "    # Create a boolean mask for the upper triangle of the matrix\n",
        "    # k=1 ensures that we don't include the diagonal (self-correlation)\n",
        "    upper_triangle_mask = np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
        "\n",
        "    # Apply the mask to the correlation matrix and stack the results\n",
        "    # This converts the matrix to a Series of correlation values for the upper triangle\n",
        "    upper_triangle_correlations = corr_matrix.where(upper_triangle_mask).stack()\n",
        "\n",
        "    # Filter the series to find correlations greater than the threshold\n",
        "    highly_correlated_series = upper_triangle_correlations[upper_triangle_correlations > threshold]\n",
        "\n",
        "    # Convert the resulting series to a DataFrame for better readability\n",
        "    highly_correlated_df = highly_correlated_series.reset_index()\n",
        "    highly_correlated_df.columns = ['Feature 1', 'Feature 2', 'Correlation']\n",
        "\n",
        "    return highly_correlated_df"
      ],
      "metadata": {
        "id": "x7wzxwXOa3Lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, use the function to find pairs with correlation > 0.85\n",
        "highly_correlated_pairs = find_highly_correlated_features(mat, threshold=0.85)\n",
        "\n",
        "print(\"Finding feature pairs with correlation > 0.2:\\n\")\n",
        "if not highly_correlated_pairs.empty:\n",
        "    print(highly_correlated_pairs)\n",
        "else:\n",
        "    print(\"No feature pairs found above the threshold.\")"
      ],
      "metadata": {
        "id": "-ysM3BSDa__o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:19.343716Z",
          "iopub.status.busy": "2022-06-15T14:49:19.343019Z",
          "iopub.status.idle": "2022-06-15T14:49:19.346058Z",
          "shell.execute_reply": "2022-06-15T14:49:19.345453Z",
          "shell.execute_reply.started": "2022-06-15T12:53:32.949462Z"
        },
        "papermill": {
          "duration": 0.077838,
          "end_time": "2022-06-15T14:49:19.346178",
          "exception": false,
          "start_time": "2022-06-15T14:49:19.268340",
          "status": "completed"
        },
        "tags": [],
        "id": "SS3L4KEm8jQ6"
      },
      "outputs": [],
      "source": [
        "# mat['LowQualFinSF']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:19.495620Z",
          "iopub.status.busy": "2022-06-15T14:49:19.494894Z",
          "iopub.status.idle": "2022-06-15T14:49:20.269641Z",
          "shell.execute_reply": "2022-06-15T14:49:20.269027Z",
          "shell.execute_reply.started": "2022-06-15T12:53:32.957657Z"
        },
        "papermill": {
          "duration": 0.853051,
          "end_time": "2022-06-15T14:49:20.269763",
          "exception": false,
          "start_time": "2022-06-15T14:49:19.416712",
          "status": "completed"
        },
        "tags": [],
        "id": "YFYvd-6C8jQ6"
      },
      "outputs": [],
      "source": [
        "# OverallQuall - SalePrice [Pearson = 0.8]\n",
        "\n",
        "figure, ax = plt.subplots(1,3, figsize = (20,8))\n",
        "sns.stripplot(data=data_w, x = 'OverallQual', y='SalePrice', ax = ax[0])\n",
        "sns.violinplot(data=data_w, x = 'OverallQual', y='SalePrice', ax = ax[1])\n",
        "sns.boxplot(data=data_w, x = 'OverallQual', y='SalePrice', ax = ax[2])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:20.424830Z",
          "iopub.status.busy": "2022-06-15T14:49:20.423781Z",
          "iopub.status.idle": "2022-06-15T14:49:21.294850Z",
          "shell.execute_reply": "2022-06-15T14:49:21.294137Z",
          "shell.execute_reply.started": "2022-06-15T12:53:33.723136Z"
        },
        "papermill": {
          "duration": 0.951852,
          "end_time": "2022-06-15T14:49:21.294977",
          "exception": false,
          "start_time": "2022-06-15T14:49:20.343125",
          "status": "completed"
        },
        "tags": [],
        "id": "ZjoXHkVx8jQ7"
      },
      "outputs": [],
      "source": [
        "# TotRmsAbvGrd - SalePrice [Pearson = 0.50]\n",
        "\n",
        "figure, ax = plt.subplots(1,3, figsize = (20,8))\n",
        "sns.stripplot(data=data_w, x = 'TotRmsAbvGrd', y='SalePrice', ax = ax[0])\n",
        "sns.violinplot(data=data_w, x = 'TotRmsAbvGrd', y='SalePrice', ax = ax[1])\n",
        "sns.boxplot(data=data_w, x = 'TotRmsAbvGrd', y='SalePrice', ax = ax[2])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:21.455285Z",
          "iopub.status.busy": "2022-06-15T14:49:21.454629Z",
          "iopub.status.idle": "2022-06-15T14:49:21.958501Z",
          "shell.execute_reply": "2022-06-15T14:49:21.959095Z",
          "shell.execute_reply.started": "2022-06-15T12:53:34.627621Z"
        },
        "papermill": {
          "duration": 0.587263,
          "end_time": "2022-06-15T14:49:21.959244",
          "exception": false,
          "start_time": "2022-06-15T14:49:21.371981",
          "status": "completed"
        },
        "tags": [],
        "id": "OwlvZxgU8jQ7"
      },
      "outputs": [],
      "source": [
        "# GrLivArea vs SalePrice [corr = 0.71]\n",
        "\n",
        "Pearson_GrLiv = 0.71\n",
        "plt.figure(figsize = (12,6))\n",
        "sns.regplot(data=data_w, x = 'GrLivArea', y='SalePrice', scatter_kws={'alpha':0.2})\n",
        "plt.title('GrLivArea vs SalePrice', fontsize = 12)\n",
        "plt.legend(['$Pearson=$ {:.2f}'.format(Pearson_GrLiv)], loc = 'best')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:22.129090Z",
          "iopub.status.busy": "2022-06-15T14:49:22.128261Z",
          "iopub.status.idle": "2022-06-15T14:49:22.609595Z",
          "shell.execute_reply": "2022-06-15T14:49:22.610112Z",
          "shell.execute_reply.started": "2022-06-15T12:53:35.121976Z"
        },
        "papermill": {
          "duration": 0.570232,
          "end_time": "2022-06-15T14:49:22.610257",
          "exception": false,
          "start_time": "2022-06-15T14:49:22.040025",
          "status": "completed"
        },
        "tags": [],
        "id": "kKAUIMN18jQ7"
      },
      "outputs": [],
      "source": [
        "Pearson_TBSF = 0.63\n",
        "plt.figure(figsize = (12,6))\n",
        "sns.regplot(data=data_w, x = 'TotalBsmtSF', y='SalePrice', scatter_kws={'alpha':0.2})\n",
        "plt.title('TotalBsmtSF vs SalePrice', fontsize = 12)\n",
        "plt.legend(['$Pearson=$ {:.2f}'.format(Pearson_TBSF)], loc = 'best')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:22.778608Z",
          "iopub.status.busy": "2022-06-15T14:49:22.777402Z",
          "iopub.status.idle": "2022-06-15T14:49:23.274256Z",
          "shell.execute_reply": "2022-06-15T14:49:23.275376Z",
          "shell.execute_reply.started": "2022-06-15T12:53:35.626174Z"
        },
        "papermill": {
          "duration": 0.585365,
          "end_time": "2022-06-15T14:49:23.275601",
          "exception": false,
          "start_time": "2022-06-15T14:49:22.690236",
          "status": "completed"
        },
        "tags": [],
        "id": "wcCmkLD18jQ7"
      },
      "outputs": [],
      "source": [
        "# YearBuilt vs SalePrice\n",
        "\n",
        "Pearson_YrBlt = 0.56\n",
        "plt.figure(figsize = (12,6))\n",
        "sns.regplot(data=data_w, x = 'YearBuilt', y='SalePrice', scatter_kws={'alpha':0.2})\n",
        "plt.title('YearBuilt vs SalePrice', fontsize = 12)\n",
        "plt.legend(['$Pearson=$ {:.2f}'.format(Pearson_YrBlt)], loc = 'best')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:23.443111Z",
          "iopub.status.busy": "2022-06-15T14:49:23.442111Z",
          "iopub.status.idle": "2022-06-15T14:49:23.925019Z",
          "shell.execute_reply": "2022-06-15T14:49:23.924250Z",
          "shell.execute_reply.started": "2022-06-15T12:53:36.154166Z"
        },
        "papermill": {
          "duration": 0.567222,
          "end_time": "2022-06-15T14:49:23.925144",
          "exception": false,
          "start_time": "2022-06-15T14:49:23.357922",
          "status": "completed"
        },
        "tags": [],
        "id": "cKAh5CHM8jQ7"
      },
      "outputs": [],
      "source": [
        "# Median of Sale Price by Year\n",
        "\n",
        "plt.figure(figsize = (10,5))\n",
        "sns.barplot(x='YrSold', y=\"SalePrice\", data = data_w, estimator = np.median)\n",
        "plt.title('Median of Sale Price by Year', fontsize = 13)\n",
        "plt.xlabel('Selling Year', fontsize = 12)\n",
        "plt.ylabel('Median of Price in $', fontsize = 12)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.082289,
          "end_time": "2022-06-15T14:49:24.089737",
          "exception": false,
          "start_time": "2022-06-15T14:49:24.007448",
          "status": "completed"
        },
        "tags": [],
        "id": "paxhvUx-8jQ7"
      },
      "source": [
        "###  DATA PREPROCESSING\n",
        "\n",
        "Now that we have some insights about data, we need to preprocess them for the modeling part. The main steps are:\n",
        "\n",
        "- Looking at potential NaN\n",
        "- Dealing with categorical features (e.g. Dummy coding)\n",
        "- Normalization\n",
        "\n",
        "N.B:\n",
        "\n",
        "Usually, in a real-world project, the test data are not available until the end. For this reason, test data should contain the same type of data of the training set to preprocess them in the same way. Here, the test set is available. It contains some observations not present in the training dataset and,the use of dummy coding could raise several issues (I spent a lot of time figuring out why I was not able to make predictions on the test set). The easiest way to solve this problem (that is not applicable if test data are not available) is to concatenate Train and Test sets, preprocess, and divide them again.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:24.260445Z",
          "iopub.status.busy": "2022-06-15T14:49:24.259371Z",
          "iopub.status.idle": "2022-06-15T14:49:24.263217Z",
          "shell.execute_reply": "2022-06-15T14:49:24.263793Z",
          "shell.execute_reply.started": "2022-06-15T12:53:36.650212Z"
        },
        "papermill": {
          "duration": 0.090077,
          "end_time": "2022-06-15T14:49:24.263940",
          "exception": false,
          "start_time": "2022-06-15T14:49:24.173863",
          "status": "completed"
        },
        "tags": [],
        "id": "4Ko-hP5q8jQ7"
      },
      "outputs": [],
      "source": [
        "#data_w=data_w[(data_w['SalePrice']<600000)].copy()\n",
        "#data_w=data_w[(data_w['GrLivArea']<4000)].copy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.columns"
      ],
      "metadata": {
        "id": "qjWmpyC3PbVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:24.432698Z",
          "iopub.status.busy": "2022-06-15T14:49:24.431674Z",
          "iopub.status.idle": "2022-06-15T14:49:24.464982Z",
          "shell.execute_reply": "2022-06-15T14:49:24.465540Z",
          "shell.execute_reply.started": "2022-06-15T12:53:36.656737Z"
        },
        "papermill": {
          "duration": 0.119396,
          "end_time": "2022-06-15T14:49:24.465691",
          "exception": false,
          "start_time": "2022-06-15T14:49:24.346295",
          "status": "completed"
        },
        "tags": [],
        "id": "94B5phTp8jQ7"
      },
      "outputs": [],
      "source": [
        "# Separating Target and Features\n",
        "\n",
        "target = data_w['SalePrice']\n",
        "test_id = test['Id']\n",
        "test = test.drop(['Id'],axis = 1)\n",
        "\n",
        "if 'SalePrice' in data_w.columns :\n",
        "   data_w.drop('SalePrice', axis = 1)\n",
        "\n",
        "if 'Order' in data_w.columns :\n",
        "  data_w.drop(['Order'], axis = 1)\n",
        "\n",
        "if 'PID' in data_w.columns :\n",
        "  data_w.drop(['PID'], axis = 1)\n",
        "\n",
        "\n",
        "# Concatenating train & test set\n",
        "\n",
        "train_test = pd.concat([data_w,test], axis=0, sort=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_test = pd.concat([data_w,test], axis=0, sort=False)"
      ],
      "metadata": {
        "id": "btpYOiBvQPZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:24.634378Z",
          "iopub.status.busy": "2022-06-15T14:49:24.633346Z",
          "iopub.status.idle": "2022-06-15T14:49:24.638681Z",
          "shell.execute_reply": "2022-06-15T14:49:24.639152Z",
          "shell.execute_reply.started": "2022-06-15T12:53:36.697177Z"
        },
        "papermill": {
          "duration": 0.090877,
          "end_time": "2022-06-15T14:49:24.639306",
          "exception": false,
          "start_time": "2022-06-15T14:49:24.548429",
          "status": "completed"
        },
        "tags": [],
        "id": "eoPS0tep8jQ7"
      },
      "outputs": [],
      "source": [
        "target.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:24.836843Z",
          "iopub.status.busy": "2022-06-15T14:49:24.835854Z",
          "iopub.status.idle": "2022-06-15T14:49:24.897440Z",
          "shell.execute_reply": "2022-06-15T14:49:24.898173Z",
          "shell.execute_reply.started": "2022-06-15T12:53:36.705686Z"
        },
        "papermill": {
          "duration": 0.171511,
          "end_time": "2022-06-15T14:49:24.898351",
          "exception": false,
          "start_time": "2022-06-15T14:49:24.726840",
          "status": "completed"
        },
        "tags": [],
        "id": "3-nlLilc8jQ7"
      },
      "outputs": [],
      "source": [
        "# Looking at NaN % within the data\n",
        "\n",
        "nan = pd.DataFrame(train_test.isna().sum(), columns = ['NaN_sum'])\n",
        "nan['feat'] = nan.index\n",
        "nan['Perc(%)'] = (nan['NaN_sum']/1460)*100\n",
        "nan = nan[nan['NaN_sum'] > 0]\n",
        "nan = nan.sort_values(by = ['NaN_sum'])\n",
        "nan['Usability'] = np.where(nan['Perc(%)'] > 20, 'Discard', 'Keep')\n",
        "nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:25.110905Z",
          "iopub.status.busy": "2022-06-15T14:49:25.109803Z",
          "iopub.status.idle": "2022-06-15T14:49:25.665515Z",
          "shell.execute_reply": "2022-06-15T14:49:25.665009Z",
          "shell.execute_reply.started": "2022-06-15T12:53:36.760413Z"
        },
        "papermill": {
          "duration": 0.665037,
          "end_time": "2022-06-15T14:49:25.665662",
          "exception": false,
          "start_time": "2022-06-15T14:49:25.000625",
          "status": "completed"
        },
        "tags": [],
        "id": "iAkloZTb8jQ7"
      },
      "outputs": [],
      "source": [
        "# Plotting Nan\n",
        "\n",
        "plt.figure(figsize = (15,5))\n",
        "sns.barplot(x = nan['feat'], y = nan['Perc(%)'])\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Features containing Nan')\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('% of Missing Data')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.085367,
          "end_time": "2022-06-15T14:49:25.836889",
          "exception": false,
          "start_time": "2022-06-15T14:49:25.751522",
          "status": "completed"
        },
        "tags": [],
        "id": "wdiIWF_S8jQ7"
      },
      "source": [
        "Are we sure that all these nans are real missing values? Looking at the given description file, we can see how the majority of these nans reflect the absence of something, and for this reason, they are not nans. We can impute them (for numerical features) or substitute them with data in the file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:26.023154Z",
          "iopub.status.busy": "2022-06-15T14:49:26.022023Z",
          "iopub.status.idle": "2022-06-15T14:49:26.119254Z",
          "shell.execute_reply": "2022-06-15T14:49:26.119769Z",
          "shell.execute_reply.started": "2022-06-15T12:53:37.175271Z"
        },
        "papermill": {
          "duration": 0.195311,
          "end_time": "2022-06-15T14:49:26.119944",
          "exception": false,
          "start_time": "2022-06-15T14:49:25.924633",
          "status": "completed"
        },
        "tags": [],
        "id": "0M0s79A_8jQ7"
      },
      "outputs": [],
      "source": [
        "# Converting non-numeric predictors stored as numbers into string\n",
        "\n",
        "train_test['MSSubClass'] = train_test['MSSubClass'].apply(str)\n",
        "train_test['YrSold'] = train_test['YrSold'].apply(str)\n",
        "train_test['MoSold'] = train_test['MoSold'].apply(str)\n",
        "\n",
        "# Filling Categorical NaN (That we know how to fill due to the description file )\n",
        "\n",
        "train_test['Functional'] = train_test['Functional'].fillna('Typ')\n",
        "train_test['Electrical'] = train_test['Electrical'].fillna(\"SBrkr\")\n",
        "train_test['KitchenQual'] = train_test['KitchenQual'].fillna(\"TA\")\n",
        "train_test['Exterior1st'] = train_test['Exterior1st'].fillna(train_test['Exterior1st'].mode()[0])\n",
        "train_test['Exterior2nd'] = train_test['Exterior2nd'].fillna(train_test['Exterior2nd'].mode()[0])\n",
        "train_test['SaleType'] = train_test['SaleType'].fillna(train_test['SaleType'].mode()[0])\n",
        "train_test[\"PoolQC\"] = train_test[\"PoolQC\"].fillna(\"None\")\n",
        "train_test[\"Alley\"] = train_test[\"Alley\"].fillna(\"None\")\n",
        "train_test['FireplaceQu'] = train_test['FireplaceQu'].fillna(\"None\")\n",
        "train_test['Fence'] = train_test['Fence'].fillna(\"None\")\n",
        "train_test['MiscFeature'] = train_test['MiscFeature'].fillna(\"None\")\n",
        "\n",
        "for col in ('GarageArea', 'GarageCars'):\n",
        "    train_test[col] = train_test[col].fillna(0)\n",
        "\n",
        "for col in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']:\n",
        "    train_test[col] = train_test[col].fillna('None')\n",
        "\n",
        "for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n",
        "    train_test[col] = train_test[col].fillna('None')\n",
        "\n",
        "    # Checking the features with NaN remained out\n",
        "\n",
        "for col in train_test:\n",
        "    if train_test[col].isna().sum() > 0:\n",
        "        print(train_test[col][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:26.304692Z",
          "iopub.status.busy": "2022-06-15T14:49:26.303662Z",
          "iopub.status.idle": "2022-06-15T14:49:26.695251Z",
          "shell.execute_reply": "2022-06-15T14:49:26.694680Z",
          "shell.execute_reply.started": "2022-06-15T12:53:37.285356Z"
        },
        "papermill": {
          "duration": 0.489984,
          "end_time": "2022-06-15T14:49:26.695376",
          "exception": false,
          "start_time": "2022-06-15T14:49:26.205392",
          "status": "completed"
        },
        "tags": [],
        "id": "VG2itWDv8jQ7"
      },
      "outputs": [],
      "source": [
        "# Removing the useless variables\n",
        "\n",
        "useless = ['GarageYrBlt','YearRemodAdd']\n",
        "train_test = train_test.drop(useless, axis = 1)\n",
        "\n",
        "# Imputing with KnnRegressor (we can also use different Imputers)\n",
        "\n",
        "def impute_knn(df):\n",
        "    ttn = train_test.select_dtypes(include=[np.number])\n",
        "    ttc = train_test.select_dtypes(exclude=[np.number])\n",
        "\n",
        "    cols_nan = ttn.columns[ttn.isna().any()].tolist()         # columns w/ nan\n",
        "    cols_no_nan = ttn.columns.difference(cols_nan).values     # columns w/n nan\n",
        "\n",
        "    for col in cols_nan:\n",
        "        imp_test = ttn[ttn[col].isna()]   # indicies which have missing data will become our test set\n",
        "        imp_train = ttn.dropna()          # all indicies which which have no missing data\n",
        "        model = KNeighborsRegressor(n_neighbors=5)  # KNR Unsupervised Approach\n",
        "        knr = model.fit(imp_train[cols_no_nan], imp_train[col])\n",
        "        ttn.loc[ttn[col].isna(), col] = knr.predict(imp_test[cols_no_nan])\n",
        "\n",
        "    return pd.concat([ttn,ttc],axis=1)\n",
        "\n",
        "train_test = impute_knn(train_test)\n",
        "\n",
        "\n",
        "objects = []\n",
        "for i in train_test.columns:\n",
        "    if train_test[i].dtype == object:\n",
        "        objects.append(i)\n",
        "train_test.update(train_test[objects].fillna('None'))\n",
        "\n",
        "# # Checking NaN presence\n",
        "\n",
        "for col in train_test:\n",
        "    if train_test[col].isna().sum() > 0:\n",
        "        print(train_test[col][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.085913,
          "end_time": "2022-06-15T14:49:26.867735",
          "exception": false,
          "start_time": "2022-06-15T14:49:26.781822",
          "status": "completed"
        },
        "tags": [],
        "id": "w8zlEECi8jQ7"
      },
      "source": [
        "### FEATURE ENGINEERING\n",
        "\n",
        "Let's create some new features combining the ones that we already have. These could help us to increase the performance of the model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:27.049493Z",
          "iopub.status.busy": "2022-06-15T14:49:27.048803Z",
          "iopub.status.idle": "2022-06-15T14:49:27.469158Z",
          "shell.execute_reply": "2022-06-15T14:49:27.468594Z",
          "shell.execute_reply.started": "2022-06-15T12:53:37.691502Z"
        },
        "papermill": {
          "duration": 0.515307,
          "end_time": "2022-06-15T14:49:27.469291",
          "exception": false,
          "start_time": "2022-06-15T14:49:26.953984",
          "status": "completed"
        },
        "tags": [],
        "id": "lyLVWPqf8jQ7"
      },
      "outputs": [],
      "source": [
        "train_test[\"SqFtPerRoom\"] = train_test[\"GrLivArea\"] / (train_test[\"TotRmsAbvGrd\"] +\n",
        "                                                       train_test[\"FullBath\"] +\n",
        "                                                       train_test[\"HalfBath\"] +\n",
        "                                                       train_test[\"KitchenAbvGr\"])\n",
        "\n",
        "train_test['Total_Home_Quality'] = train_test['OverallQual'] + train_test['OverallCond']\n",
        "\n",
        "train_test['Total_Bathrooms'] = (train_test['FullBath'] + (0.5 * train_test['HalfBath']) +\n",
        "                               train_test['BsmtFullBath'] + (0.5 * train_test['BsmtHalfBath']))\n",
        "\n",
        "train_test[\"HighQualSF\"] = train_test[\"GrLivArea\"]+train_test[\"1stFlrSF\"] + train_test[\"2ndFlrSF\"]+0.5*train_test[\"GarageArea\"]+0.5*train_test[\"TotalBsmtSF\"]+1*train_test[\"MasVnrArea\"]\n",
        "#train_test[\"LowQualSF\"] = train_test[\"MasVnrArea\"] +train_test[\"WoodDeckSF\"]+train_test[\"OpenPorchSF\"]+train_test[\"EnclosedPorch\"]+train_test[\"3SsnPorch\"]+train_test[\"ScreenPorch\"]+train_test[\"PoolArea\"]\n",
        "#train_test[\"QualityproductSF\"] = train_test[\"GrLivArea\"]*(train_test['OverallQual'])\n",
        "#train_test[\"LowQualSF\"] = train_test[\"MasVnrArea\"]+train_test[\"WoodDeckSF\"] + train_test[\"OpenPorchSF\"]+train_test[\"PoolArea\"]\n",
        "\n",
        "train_test[\"Age\"] = pd.to_numeric(train_test[\"YrSold\"])-pd.to_numeric(train_test[\"YearBuilt\"])\n",
        "\n",
        "# Not sure why this is here. Since we already removed YearRemodAdd in the last cell\n",
        "#train_test[\"Renovate\"] = pd.to_numeric(train_test[\"YearRemodAdd\"])-pd.to_numeric(train_test[\"YearBuilt\"])\n",
        "\n",
        "# Converting non-numeric predictors stored as numbers into string\n",
        "# Convert 'MSSubClass', 'YrSold', 'MoSold' to string *before* creating dummy variables\n",
        "train_test['MSSubClass'] = train_test['MSSubClass'].apply(str)\n",
        "train_test['YrSold'] = train_test['YrSold'].apply(str)\n",
        "train_test['MoSold'] = train_test['MoSold'].apply(str)\n",
        "\n",
        "# Remove the 'Id' column before creating dummy variables\n",
        "if 'Id' in train_test.columns:\n",
        "    train_test = train_test.drop('Id', axis=1)\n",
        "\n",
        "# Creating dummy variables from categorical features\n",
        "train_test_dummy = pd.get_dummies(train_test)\n",
        "\n",
        "\n",
        "# Fetch all numeric features AFTER creating dummies\n",
        "# This ensures that only truly numerical columns remain after one-hot encoding\n",
        "numeric_features = train_test_dummy.select_dtypes(include=np.number).columns\n",
        "\n",
        "\n",
        "skewed_features = train_test_dummy[numeric_features].apply(lambda x: skew(x)).sort_values(ascending=False)\n",
        "high_skew = skewed_features[skewed_features > 0.5]\n",
        "skew_index = high_skew.index\n",
        "\n",
        "# Normalize skewed features using log_transformation\n",
        "\n",
        "for i in skew_index:\n",
        "    # Add a small constant to avoid log(0) if necessary, although log1p handles 0\n",
        "    train_test_dummy[i] = np.log1p(train_test_dummy[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.084915,
          "end_time": "2022-06-15T14:49:27.638856",
          "exception": false,
          "start_time": "2022-06-15T14:49:27.553941",
          "status": "completed"
        },
        "tags": [],
        "id": "dGnLNuXY8jQ8"
      },
      "source": [
        "Now let's try to tranform our target distribution into a normal one. To do this we use a log transformation. We will use qq-plot to see the transformation effect.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:27.816464Z",
          "iopub.status.busy": "2022-06-15T14:49:27.815822Z",
          "iopub.status.idle": "2022-06-15T14:49:28.331032Z",
          "shell.execute_reply": "2022-06-15T14:49:28.331522Z",
          "shell.execute_reply.started": "2022-06-15T12:53:38.134113Z"
        },
        "papermill": {
          "duration": 0.608048,
          "end_time": "2022-06-15T14:49:28.331713",
          "exception": false,
          "start_time": "2022-06-15T14:49:27.723665",
          "status": "completed"
        },
        "tags": [],
        "id": "gM9wlJNR8jQ8"
      },
      "outputs": [],
      "source": [
        "# SalePrice before transformation\n",
        "\n",
        "fig, ax = plt.subplots(1,2, figsize= (15,5))\n",
        "fig.suptitle(\" qq-plot & distribution SalePrice \", fontsize= 15)\n",
        "\n",
        "sm.qqplot(target, stats.t, distargs=(4,),fit=True, line=\"45\", ax = ax[0])\n",
        "\n",
        "sns.distplot(target, kde = True, hist=True, fit = norm, ax = ax[1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:28.529775Z",
          "iopub.status.busy": "2022-06-15T14:49:28.523583Z",
          "iopub.status.idle": "2022-06-15T14:49:29.059860Z",
          "shell.execute_reply": "2022-06-15T14:49:29.059173Z",
          "shell.execute_reply.started": "2022-06-15T12:53:38.670185Z"
        },
        "papermill": {
          "duration": 0.638722,
          "end_time": "2022-06-15T14:49:29.060019",
          "exception": false,
          "start_time": "2022-06-15T14:49:28.421297",
          "status": "completed"
        },
        "tags": [],
        "id": "JbiIAH5y8jQ8"
      },
      "outputs": [],
      "source": [
        "# SalePrice after transformation\n",
        "\n",
        "target_log = np.log1p(target)\n",
        "\n",
        "fig, ax = plt.subplots(1,2, figsize= (15,5))\n",
        "fig.suptitle(\"qq-plot & distribution SalePrice \", fontsize= 15)\n",
        "\n",
        "sm.qqplot(target_log, stats.t, distargs=(4,),fit=True, line=\"45\", ax = ax[0])\n",
        "sns.distplot(target_log, kde = True, hist=True, fit = norm, ax = ax[1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:29.294156Z",
          "iopub.status.busy": "2022-06-15T14:49:29.288624Z",
          "iopub.status.idle": "2022-06-15T14:49:29.831243Z",
          "shell.execute_reply": "2022-06-15T14:49:29.830609Z",
          "shell.execute_reply.started": "2022-06-15T12:53:39.231599Z"
        },
        "papermill": {
          "duration": 0.682476,
          "end_time": "2022-06-15T14:49:29.831371",
          "exception": false,
          "start_time": "2022-06-15T14:49:29.148895",
          "status": "completed"
        },
        "tags": [],
        "id": "Y6usXEyf8jQ8"
      },
      "outputs": [],
      "source": [
        "# SalePrice after transformation\n",
        "\n",
        "HighQualSF_log = np.log1p(train_test[\"HighQualSF\"])\n",
        "\n",
        "fig, ax = plt.subplots(1,2, figsize= (15,5))\n",
        "fig.suptitle(\"qq-plot & distribution SalePrice \", fontsize= 15)\n",
        "\n",
        "sm.qqplot(HighQualSF_log, stats.t, distargs=(4,),fit=True, line=\"45\", ax = ax[0])\n",
        "sns.distplot(HighQualSF_log, kde = True, hist=True, fit = norm, ax = ax[1])\n",
        "plt.show()\n",
        "\n",
        "train_test[\"HighQualSF\"]= HighQualSF_log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:30.018798Z",
          "iopub.status.busy": "2022-06-15T14:49:30.018150Z",
          "iopub.status.idle": "2022-06-15T14:49:30.556649Z",
          "shell.execute_reply": "2022-06-15T14:49:30.556020Z",
          "shell.execute_reply.started": "2022-06-15T12:53:39.785115Z"
        },
        "papermill": {
          "duration": 0.632268,
          "end_time": "2022-06-15T14:49:30.556762",
          "exception": false,
          "start_time": "2022-06-15T14:49:29.924494",
          "status": "completed"
        },
        "tags": [],
        "id": "Ikl-6BW78jQ8"
      },
      "outputs": [],
      "source": [
        "# GrLivArea before transformation\n",
        "\n",
        "fig, ax = plt.subplots(1,2, figsize= (15,5))\n",
        "fig.suptitle(\" qq-plot & distribution GrLivArea \", fontsize= 15)\n",
        "\n",
        "sm.qqplot(train_test[\"GrLivArea\"], stats.t, distargs=(4,),fit=True, line=\"45\", ax = ax[0])\n",
        "\n",
        "sns.distplot(train_test[\"GrLivArea\"], kde = True, hist=True, fit = norm, ax = ax[1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:30.742052Z",
          "iopub.status.busy": "2022-06-15T14:49:30.741288Z",
          "iopub.status.idle": "2022-06-15T14:49:31.253198Z",
          "shell.execute_reply": "2022-06-15T14:49:31.253832Z",
          "shell.execute_reply.started": "2022-06-15T12:53:40.324122Z"
        },
        "papermill": {
          "duration": 0.606781,
          "end_time": "2022-06-15T14:49:31.253987",
          "exception": false,
          "start_time": "2022-06-15T14:49:30.647206",
          "status": "completed"
        },
        "tags": [],
        "id": "xZPir19n8jQ8"
      },
      "outputs": [],
      "source": [
        "# SalePrice after transformation\n",
        "\n",
        "GrLivArea_log = np.log1p(train_test[\"GrLivArea\"])\n",
        "\n",
        "fig, ax = plt.subplots(1,2, figsize= (15,5))\n",
        "fig.suptitle(\"qq-plot & distribution SalePrice \", fontsize= 15)\n",
        "\n",
        "sm.qqplot(GrLivArea_log, stats.t, distargs=(4,),fit=True, line=\"45\", ax = ax[0])\n",
        "sns.distplot(GrLivArea_log, kde = True, hist=True, fit = norm, ax = ax[1])\n",
        "plt.show()\n",
        "\n",
        "train_test[\"GrLivArea\"]= GrLivArea_log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.092533,
          "end_time": "2022-06-15T14:49:31.440579",
          "exception": false,
          "start_time": "2022-06-15T14:49:31.348046",
          "status": "completed"
        },
        "tags": [],
        "id": "LZLzlKjo8jQ8"
      },
      "source": [
        "### MODELING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:31.629474Z",
          "iopub.status.busy": "2022-06-15T14:49:31.628821Z",
          "iopub.status.idle": "2022-06-15T14:49:34.466166Z",
          "shell.execute_reply": "2022-06-15T14:49:34.466741Z",
          "shell.execute_reply.started": "2022-06-15T12:53:41.208974Z"
        },
        "papermill": {
          "duration": 2.933324,
          "end_time": "2022-06-15T14:49:34.466905",
          "exception": false,
          "start_time": "2022-06-15T14:49:31.533581",
          "status": "completed"
        },
        "tags": [],
        "id": "WcYGzD708jQ_"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "import xgboost as xgb\n",
        "from catboost import Pool\n",
        "from sklearn.svm import SVR\n",
        "from catboost import CatBoostRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from mlxtend.regressor import StackingRegressor\n",
        "from sklearn.linear_model import LinearRegression, BayesianRidge\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_squared_log_error\n",
        "from sklearn.ensemble import VotingRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:34.659214Z",
          "iopub.status.busy": "2022-06-15T14:49:34.658190Z",
          "iopub.status.idle": "2022-06-15T14:49:34.682176Z",
          "shell.execute_reply": "2022-06-15T14:49:34.682786Z",
          "shell.execute_reply.started": "2022-06-15T12:53:41.221406Z"
        },
        "papermill": {
          "duration": 0.12172,
          "end_time": "2022-06-15T14:49:34.682939",
          "exception": false,
          "start_time": "2022-06-15T14:49:34.561219",
          "status": "completed"
        },
        "tags": [],
        "id": "fxig3StT8jQ_"
      },
      "outputs": [],
      "source": [
        "# Train-Test separation\n",
        "\n",
        "train = train_test_dummy.iloc[0:1460]\n",
        "test = train_test_dummy.iloc[1460:]\n",
        "\n",
        "# Reset the index of the 'test' DataFrame to align with the 'test_id' Series\n",
        "test = test.reset_index(drop=True)\n",
        "\n",
        "test['Id'] = test_id\n",
        "\n",
        "# Creation of the RMSE metric:\n",
        "\n",
        "def rmse(y, y_pred):\n",
        "    return np.sqrt(mean_squared_error(y, y_pred))\n",
        "\n",
        "def cv_rmse(model):\n",
        "    rmse = np.sqrt(-cross_val_score(model, train, target_log, scoring=\"neg_mean_squared_error\", cv=kf))\n",
        "    return (rmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:34.874587Z",
          "iopub.status.busy": "2022-06-15T14:49:34.873546Z",
          "iopub.status.idle": "2022-06-15T14:49:34.880248Z",
          "shell.execute_reply": "2022-06-15T14:49:34.880789Z",
          "shell.execute_reply.started": "2022-06-15T12:53:41.250719Z"
        },
        "papermill": {
          "duration": 0.103728,
          "end_time": "2022-06-15T14:49:34.880947",
          "exception": false,
          "start_time": "2022-06-15T14:49:34.777219",
          "status": "completed"
        },
        "tags": [],
        "id": "XzCochAF8jQ_"
      },
      "outputs": [],
      "source": [
        "# # 10 Fold Cross validation\n",
        "\n",
        "# kf = KFold(n_splits=10, random_state=42, shuffle=True)\n",
        "\n",
        "# cv_scores = []\n",
        "# cv_std = []\n",
        "\n",
        "# baseline_models = ['Linear_Reg.','Bayesian_Ridge_Reg.','LGBM_Reg.','SVR',\n",
        "#                    'Dec_Tree_Reg.','Random_Forest_Reg.', 'XGB_Reg.',\n",
        "#                    'Grad_Boost_Reg.','Cat_Boost_Reg.','Stacked_Reg.']\n",
        "\n",
        "# # Linear Regression\n",
        "\n",
        "# lreg = LinearRegression()\n",
        "# score_lreg = cv_rmse(lreg)\n",
        "# cv_scores.append(score_lreg.mean())\n",
        "# cv_std.append(score_lreg.std())\n",
        "\n",
        "# # Bayesian Ridge Regression\n",
        "\n",
        "# brr = BayesianRidge(compute_score=True)\n",
        "# score_brr = cv_rmse(brr)\n",
        "# cv_scores.append(score_brr.mean())\n",
        "# cv_std.append(score_brr.std())\n",
        "\n",
        "# # Light Gradient Boost Regressor\n",
        "\n",
        "# l_gbm = LGBMRegressor(objective='regression')\n",
        "# score_l_gbm = cv_rmse(l_gbm)\n",
        "# cv_scores.append(score_l_gbm.mean())\n",
        "# cv_std.append(score_l_gbm.std())\n",
        "\n",
        "# # Support Vector Regression\n",
        "\n",
        "# svr = SVR()\n",
        "# score_svr = cv_rmse(svr)\n",
        "# cv_scores.append(score_svr.mean())\n",
        "# cv_std.append(score_svr.std())\n",
        "\n",
        "# # Decision Tree Regressor\n",
        "\n",
        "# dtr = DecisionTreeRegressor()\n",
        "# score_dtr = cv_rmse(dtr)\n",
        "# cv_scores.append(score_dtr.mean())\n",
        "# cv_std.append(score_dtr.std())\n",
        "\n",
        "# # Random Forest Regressor\n",
        "\n",
        "# rfr = RandomForestRegressor()\n",
        "# score_rfr = cv_rmse(rfr)\n",
        "# cv_scores.append(score_rfr.mean())\n",
        "# cv_std.append(score_rfr.std())\n",
        "\n",
        "# # XGB Regressor\n",
        "\n",
        "# xgb = xgb.XGBRegressor()\n",
        "# score_xgb = cv_rmse(xgb)\n",
        "# cv_scores.append(score_xgb.mean())\n",
        "# cv_std.append(score_xgb.std())\n",
        "\n",
        "# # Gradient Boost Regressor\n",
        "\n",
        "# gbr = GradientBoostingRegressor()\n",
        "# score_gbr = cv_rmse(gbr)\n",
        "# cv_scores.append(score_gbr.mean())\n",
        "# cv_std.append(score_gbr.std())\n",
        "\n",
        "# # Cat Boost Regressor\n",
        "\n",
        "# catb = CatBoostRegressor()\n",
        "# score_catb = cv_rmse(catb)\n",
        "# cv_scores.append(score_catb.mean())\n",
        "# cv_std.append(score_catb.std())\n",
        "\n",
        "# # Stacked Regressor\n",
        "\n",
        "# stack_gen = StackingRegressor(regressors=(CatBoostRegressor(),\n",
        "#                                           LinearRegression(),\n",
        "#                                           BayesianRidge(),\n",
        "#                                           GradientBoostingRegressor()),\n",
        "#                               meta_regressor = CatBoostRegressor(),\n",
        "#                               use_features_in_secondary = True)\n",
        "\n",
        "# score_stack_gen = cv_rmse(stack_gen)\n",
        "# cv_scores.append(score_stack_gen.mean())\n",
        "# cv_std.append(score_stack_gen.std())\n",
        "\n",
        "# # vote_gen = VotingRegressor(estimators=[('Cat_Boost_Reg', CatBoostRegressor()),\n",
        "# #                                              ('Linear_Reg', LinearRegression()),\n",
        "# #                                              ('Bayesian_Ridge_Reg', BayesianRidge()),\n",
        "# #                                              ('Grad_Boost_Reg', GradientBoostingRegressor()),\n",
        "# #                                              ('LGBM_Reg', LGBMRegressor(objective='regression'))\n",
        "# #                                             ])\n",
        "\n",
        "# # score_vote_gen = cv_rmse(vote_gen)\n",
        "# # cv_scores.append(score_vote_gen.mean())\n",
        "# # cv_std.append(score_vote_gen.std())\n",
        "\n",
        "# final_cv_score = pd.DataFrame(baseline_models, columns = ['Regressors'])\n",
        "# final_cv_score['RMSE_mean'] = cv_scores\n",
        "# final_cv_score['RMSE_std'] = cv_std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:35.072389Z",
          "iopub.status.busy": "2022-06-15T14:49:35.071376Z",
          "iopub.status.idle": "2022-06-15T14:49:35.075178Z",
          "shell.execute_reply": "2022-06-15T14:49:35.075812Z",
          "shell.execute_reply.started": "2022-06-15T12:53:41.264409Z"
        },
        "papermill": {
          "duration": 0.101156,
          "end_time": "2022-06-15T14:49:35.075969",
          "exception": false,
          "start_time": "2022-06-15T14:49:34.974813",
          "status": "completed"
        },
        "tags": [],
        "id": "9DfvMBHv8jQ_"
      },
      "outputs": [],
      "source": [
        "# final_cv_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:35.264876Z",
          "iopub.status.busy": "2022-06-15T14:49:35.263399Z",
          "iopub.status.idle": "2022-06-15T14:49:35.266977Z",
          "shell.execute_reply": "2022-06-15T14:49:35.267475Z",
          "shell.execute_reply.started": "2022-06-15T12:53:41.277119Z"
        },
        "papermill": {
          "duration": 0.099461,
          "end_time": "2022-06-15T14:49:35.267635",
          "exception": false,
          "start_time": "2022-06-15T14:49:35.168174",
          "status": "completed"
        },
        "tags": [],
        "id": "xuG92VQs8jQ_"
      },
      "outputs": [],
      "source": [
        "# plt.figure(figsize = (12,8))\n",
        "# sns.barplot(final_cv_score['Regressors'],final_cv_score['RMSE_mean'])\n",
        "# plt.xlabel('Regressors', fontsize = 12)\n",
        "# plt.ylabel('CV_Mean_RMSE', fontsize = 12)\n",
        "# plt.xticks(rotation=45)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:35.456100Z",
          "iopub.status.busy": "2022-06-15T14:49:35.455395Z",
          "iopub.status.idle": "2022-06-15T14:49:43.108198Z",
          "shell.execute_reply": "2022-06-15T14:49:43.107417Z",
          "shell.execute_reply.started": "2022-06-15T12:53:41.290090Z"
        },
        "papermill": {
          "duration": 7.748317,
          "end_time": "2022-06-15T14:49:43.108325",
          "exception": false,
          "start_time": "2022-06-15T14:49:35.360008",
          "status": "completed"
        },
        "tags": [],
        "id": "yJZWPG7F8jQ_"
      },
      "outputs": [],
      "source": [
        "# Train-Test split the data\n",
        "\n",
        "X_train,X_val,y_train,y_val = train_test_split(train,target_log,test_size = 0.5,random_state=42)\n",
        "\n",
        "X_train,y_train =train,target_log\n",
        "\n",
        "# Cat Boost Regressor\n",
        "\n",
        "cat = CatBoostRegressor()\n",
        "cat_model = cat.fit(X_train,y_train,\n",
        "                     eval_set = (X_val,y_val),\n",
        "                     plot=True,\n",
        "                     verbose = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:43.389781Z",
          "iopub.status.busy": "2022-06-15T14:49:43.362135Z",
          "iopub.status.idle": "2022-06-15T14:49:43.486127Z",
          "shell.execute_reply": "2022-06-15T14:49:43.485407Z",
          "shell.execute_reply.started": "2022-06-15T12:53:49.286750Z"
        },
        "papermill": {
          "duration": 0.261169,
          "end_time": "2022-06-15T14:49:43.486249",
          "exception": false,
          "start_time": "2022-06-15T14:49:43.225080",
          "status": "completed"
        },
        "tags": [],
        "id": "UdLFPyVP8jQ_"
      },
      "outputs": [],
      "source": [
        "cat_pred = cat_model.predict(X_val)\n",
        "cat_score = rmse(y_val, cat_pred)\n",
        "cat_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.112836,
          "end_time": "2022-06-15T14:49:43.711165",
          "exception": false,
          "start_time": "2022-06-15T14:49:43.598329",
          "status": "completed"
        },
        "tags": [],
        "id": "ZnffGlmz8jQ_"
      },
      "source": [
        "Now let's take a look at the top 20 most important variables for our model. This could give us further insight into the functioning of the algorithm and how and which data it uses most to arrive at the final prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:43.940608Z",
          "iopub.status.busy": "2022-06-15T14:49:43.939571Z",
          "iopub.status.idle": "2022-06-15T14:49:43.965699Z",
          "shell.execute_reply": "2022-06-15T14:49:43.964675Z",
          "shell.execute_reply.started": "2022-06-15T12:53:49.435120Z"
        },
        "papermill": {
          "duration": 0.142194,
          "end_time": "2022-06-15T14:49:43.965839",
          "exception": false,
          "start_time": "2022-06-15T14:49:43.823645",
          "status": "completed"
        },
        "tags": [],
        "id": "gV4HTgEF8jQ_"
      },
      "outputs": [],
      "source": [
        "# Features' importance of our model\n",
        "\n",
        "feat_imp = cat_model.get_feature_importance(prettified=True)\n",
        "feat_imp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:44.230207Z",
          "iopub.status.busy": "2022-06-15T14:49:44.201195Z",
          "iopub.status.idle": "2022-06-15T14:49:44.703985Z",
          "shell.execute_reply": "2022-06-15T14:49:44.704553Z",
          "shell.execute_reply.started": "2022-06-15T12:53:49.464105Z"
        },
        "papermill": {
          "duration": 0.625646,
          "end_time": "2022-06-15T14:49:44.704703",
          "exception": false,
          "start_time": "2022-06-15T14:49:44.079057",
          "status": "completed"
        },
        "tags": [],
        "id": "hMtjve6x8jRA"
      },
      "outputs": [],
      "source": [
        "# Plotting top 20 features' importance\n",
        "\n",
        "plt.figure(figsize = (12,8))\n",
        "sns.barplot(x=feat_imp['Importances'][:40],y=feat_imp['Feature Id'][:40], orient = 'h')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:44.987990Z",
          "iopub.status.busy": "2022-06-15T14:49:44.982078Z",
          "iopub.status.idle": "2022-06-15T14:49:48.312488Z",
          "shell.execute_reply": "2022-06-15T14:49:48.313081Z",
          "shell.execute_reply.started": "2022-06-15T12:53:49.968744Z"
        },
        "papermill": {
          "duration": 3.489727,
          "end_time": "2022-06-15T14:49:48.313236",
          "exception": false,
          "start_time": "2022-06-15T14:49:44.823509",
          "status": "completed"
        },
        "tags": [],
        "id": "cM6bWL4o8jRA"
      },
      "outputs": [],
      "source": [
        "# Feature importance Interactive Plot\n",
        "\n",
        "train_pool = Pool(X_train)\n",
        "val_pool = Pool(X_val)\n",
        "\n",
        "explainer = shap.TreeExplainer(cat_model) # insert your model\n",
        "shap_values = explainer.shap_values(train_pool) # insert your train Pool object\n",
        "\n",
        "shap.initjs()\n",
        "shap.force_plot(explainer.expected_value, shap_values[:200,:], X_train.iloc[:200,:])\n",
        "\n",
        "# The plot represents just a slice of the Training data (200 observations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:48.739691Z",
          "iopub.status.busy": "2022-06-15T14:49:48.739030Z",
          "iopub.status.idle": "2022-06-15T14:49:49.746305Z",
          "shell.execute_reply": "2022-06-15T14:49:49.745651Z",
          "shell.execute_reply.started": "2022-06-15T12:53:53.171861Z"
        },
        "papermill": {
          "duration": 1.212316,
          "end_time": "2022-06-15T14:49:49.746421",
          "exception": false,
          "start_time": "2022-06-15T14:49:48.534105",
          "status": "completed"
        },
        "tags": [],
        "id": "nPiYc-xB8jRA"
      },
      "outputs": [],
      "source": [
        "shap.summary_plot(shap_values, X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.196858,
          "end_time": "2022-06-15T14:49:50.147414",
          "exception": false,
          "start_time": "2022-06-15T14:49:49.950556",
          "status": "completed"
        },
        "tags": [],
        "id": "_ht-lOO38jRA"
      },
      "source": [
        "The above diagram represents each observation (x-axis) for the feature presented (y-axis). The x location of each dot on the x-axis reflects the impact of that feature on the model's predictions, while the color of the dot represents the value of that feature for that exact observation. Dots that pile up on the line show density. Here we can see how features such as 'BsmtFinType1_GLQ' or 'BsmtQual_Ex', differently from 'GrLivArea' and 'OverallQual', do not contribute significantly in producing the final predictions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.195893,
          "end_time": "2022-06-15T14:49:50.540978",
          "exception": false,
          "start_time": "2022-06-15T14:49:50.345085",
          "status": "completed"
        },
        "tags": [],
        "id": "n9v4eDVC8jRA"
      },
      "source": [
        " N.B: Catboost comes with a great method: ***get_feature_importance***. This method can be used to find important interactions among features. This is a huge advantage because it can give us insights about possible new features to create that can improve the performance.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:51.014110Z",
          "iopub.status.busy": "2022-06-15T14:49:50.975625Z",
          "iopub.status.idle": "2022-06-15T14:49:51.259950Z",
          "shell.execute_reply": "2022-06-15T14:49:51.259201Z",
          "shell.execute_reply.started": "2022-06-15T12:53:54.255085Z"
        },
        "papermill": {
          "duration": 0.523709,
          "end_time": "2022-06-15T14:49:51.260070",
          "exception": false,
          "start_time": "2022-06-15T14:49:50.736361",
          "status": "completed"
        },
        "tags": [],
        "id": "sPozS6fv8jRA"
      },
      "outputs": [],
      "source": [
        "# Features' Interactions\n",
        "\n",
        "train_data = Pool(X_train)\n",
        "\n",
        "interaction = cat_model.get_feature_importance(train_data, type=\"Interaction\")\n",
        "column_names = X_train.columns.values\n",
        "interaction = pd.DataFrame(interaction, columns=[\"feature1\", \"feature2\", \"importance\"])\n",
        "interaction.feature1 = interaction.feature1.apply(lambda l: column_names[int(l)])\n",
        "interaction.feature2 = interaction.feature2.apply(lambda l: column_names[int(l)])\n",
        "interaction.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.207307,
          "end_time": "2022-06-15T14:49:51.667781",
          "exception": false,
          "start_time": "2022-06-15T14:49:51.460474",
          "status": "completed"
        },
        "tags": [],
        "id": "nn0shDYi8jRA"
      },
      "source": [
        "Which are the deafult parameters used by CaboostRegressor? This is our real baseline, now we need to optimize the hyperparameters trying to tune the model to obtain a better performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:52.083884Z",
          "iopub.status.busy": "2022-06-15T14:49:52.082801Z",
          "iopub.status.idle": "2022-06-15T14:49:52.088215Z",
          "shell.execute_reply": "2022-06-15T14:49:52.087707Z",
          "shell.execute_reply.started": "2022-06-15T12:53:54.592372Z"
        },
        "papermill": {
          "duration": 0.216763,
          "end_time": "2022-06-15T14:49:52.088331",
          "exception": false,
          "start_time": "2022-06-15T14:49:51.871568",
          "status": "completed"
        },
        "tags": [],
        "id": "mAnj5ren8jRA"
      },
      "outputs": [],
      "source": [
        "# Catboost default paramters\n",
        "\n",
        "cat_model.get_all_params()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.198627,
          "end_time": "2022-06-15T14:49:52.486362",
          "exception": false,
          "start_time": "2022-06-15T14:49:52.287735",
          "status": "completed"
        },
        "tags": [],
        "id": "e2P5ZL148jRA"
      },
      "source": [
        "### Hyperparameter Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:52.896186Z",
          "iopub.status.busy": "2022-06-15T14:49:52.895109Z",
          "iopub.status.idle": "2022-06-15T14:49:52.897649Z",
          "shell.execute_reply": "2022-06-15T14:49:52.897076Z",
          "shell.execute_reply.started": "2022-06-15T12:53:54.602060Z"
        },
        "papermill": {
          "duration": 0.211022,
          "end_time": "2022-06-15T14:49:52.897814",
          "exception": false,
          "start_time": "2022-06-15T14:49:52.686792",
          "status": "completed"
        },
        "tags": [],
        "id": "KhxWYCLo8jRA"
      },
      "outputs": [],
      "source": [
        "# # Preforming a Random Grid Search to find the best combination of parameters\n",
        "\n",
        "# grid = {'iterations': [16000,20000,25000,30000],\n",
        "#         'learning_rate': [0.04,0.05,0.01,0.002,0.005],\n",
        "#         'depth': [1,2,3,4,5,6,7,8],\n",
        "#         'l2_leaf_reg': [1, 3, 5, 9,13,15,17],\n",
        "#         'max_leaves' : [8,10,12,14,16,32,64],\n",
        "#         'early_stopping_rounds': [200],\n",
        "#         'model_size_reg' : [0.2,0.5,0.7,0.9]}\n",
        "\n",
        "# final_model = CatBoostRegressor()\n",
        "# randomized_search_result = final_model.randomized_search(grid,\n",
        "#                                                    X = X_train,\n",
        "#                                                    y= y_train,\n",
        "#                                                    verbose = False,\n",
        "#                                                    plot=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:53.304256Z",
          "iopub.status.busy": "2022-06-15T14:49:53.303048Z",
          "iopub.status.idle": "2022-06-15T14:49:53.305909Z",
          "shell.execute_reply": "2022-06-15T14:49:53.305340Z",
          "shell.execute_reply.started": "2022-06-15T13:17:52.426624Z"
        },
        "papermill": {
          "duration": 0.208909,
          "end_time": "2022-06-15T14:49:53.306036",
          "exception": false,
          "start_time": "2022-06-15T14:49:53.097127",
          "status": "completed"
        },
        "tags": [],
        "id": "FIvlvCmh8jRA"
      },
      "outputs": [],
      "source": [
        "# randomized_search_result['params']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T14:49:53.721414Z",
          "iopub.status.busy": "2022-06-15T14:49:53.720368Z",
          "iopub.status.idle": "2022-06-15T15:16:55.935910Z",
          "shell.execute_reply": "2022-06-15T15:16:55.936466Z"
        },
        "papermill": {
          "duration": 1622.430416,
          "end_time": "2022-06-15T15:16:55.936638",
          "exception": false,
          "start_time": "2022-06-15T14:49:53.506222",
          "status": "completed"
        },
        "tags": [],
        "id": "G9yzc5LZ8jRA"
      },
      "outputs": [],
      "source": [
        "# Final Cat-Boost Regressor\n",
        "\n",
        "params = {'max_leaves': 8,\n",
        "          'depth': 3,\n",
        "          'od_wait': 200,\n",
        "          'l2_leaf_reg': 3,\n",
        "          'iterations': 200000,\n",
        "          'model_size_reg': 0.7,\n",
        "          'learning_rate': 0.05,\n",
        "          'random_seed': 42 }\n",
        "\n",
        "# params = {'iterations': 4000,\n",
        "#           'learning_rate': 0.002,\n",
        "#           'depth': 4,\n",
        "#           'l2_leaf_reg': 1,\n",
        "#           'eval_metric':'RMSE',\n",
        "#           'max_leaves':16,\n",
        "#           'early_stopping_rounds': 200,\n",
        "#           'model_size_reg':0.7,\n",
        "#           'verbose': 200,\n",
        "#           'random_seed': 42}\n",
        "\n",
        "cat_f = CatBoostRegressor(**params)\n",
        "cat_model_f = cat_f.fit(X_train,y_train,\n",
        "                     eval_set = (X_val,y_val),\n",
        "                     plot=True,\n",
        "                     verbose = False)\n",
        "\n",
        "catf_pred = cat_model_f.predict(X_val)\n",
        "catf_score = rmse(y_val, catf_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T15:16:56.413508Z",
          "iopub.status.busy": "2022-06-15T15:16:56.412639Z",
          "iopub.status.idle": "2022-06-15T15:16:56.416208Z",
          "shell.execute_reply": "2022-06-15T15:16:56.416774Z",
          "shell.execute_reply.started": "2022-06-15T14:18:29.076153Z"
        },
        "papermill": {
          "duration": 0.253503,
          "end_time": "2022-06-15T15:16:56.416921",
          "exception": false,
          "start_time": "2022-06-15T15:16:56.163418",
          "status": "completed"
        },
        "tags": [],
        "id": "oKwghBsE8jRA"
      },
      "outputs": [],
      "source": [
        "catf_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.220066,
          "end_time": "2022-06-15T15:16:56.856506",
          "exception": false,
          "start_time": "2022-06-15T15:16:56.636440",
          "status": "completed"
        },
        "tags": [],
        "id": "7XmDxSls8jRA"
      },
      "source": [
        "### SUBMISSION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T15:16:57.341917Z",
          "iopub.status.busy": "2022-06-15T15:16:57.336369Z",
          "iopub.status.idle": "2022-06-15T15:16:57.524931Z",
          "shell.execute_reply": "2022-06-15T15:16:57.524221Z"
        },
        "papermill": {
          "duration": 0.448429,
          "end_time": "2022-06-15T15:16:57.525045",
          "exception": false,
          "start_time": "2022-06-15T15:16:57.076616",
          "status": "completed"
        },
        "tags": [],
        "id": "8222p9q_8jRA"
      },
      "outputs": [],
      "source": [
        "# Test CSV Submission\n",
        "\n",
        "test_pred = cat_model_f.predict(test)\n",
        "submission = pd.DataFrame(test_id, columns = ['Id'])\n",
        "test_pred = np.expm1(test_pred)\n",
        "submission['SalePrice'] = test_pred\n",
        "submission.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T15:16:57.972025Z",
          "iopub.status.busy": "2022-06-15T15:16:57.971164Z",
          "iopub.status.idle": "2022-06-15T15:16:58.242399Z",
          "shell.execute_reply": "2022-06-15T15:16:58.242927Z"
        },
        "papermill": {
          "duration": 0.498754,
          "end_time": "2022-06-15T15:16:58.243088",
          "exception": false,
          "start_time": "2022-06-15T15:16:57.744334",
          "status": "completed"
        },
        "tags": [],
        "id": "leGDKEud8jRA"
      },
      "outputs": [],
      "source": [
        "# Saving the results in a csv file\n",
        "\n",
        "submission.to_csv(\"submission.csv\", index = False, header = True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "papermill": {
      "duration": 1673.245227,
      "end_time": "2022-06-15T15:16:59.732228",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2022-06-15T14:49:06.487001",
      "version": "2.1.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}